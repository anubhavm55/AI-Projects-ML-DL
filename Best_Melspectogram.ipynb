{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Best_Melspectogram.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnpbdTd72-gy"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "from PIL import Image\n",
        "import pathlib\n",
        "import csv \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras import layers\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') \n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import random\n",
        "from keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
        "from tensorflow.keras.layers import Conv2D, Activation,AveragePooling2D,MaxPooling2D,GlobalAveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J5eS4j93LOu"
      },
      "source": [
        "path_to_train_wav='/content/drive/MyDrive/prism_dataset/train_wav'\n",
        "path_to_test_wav='/content/drive/MyDrive/prism_dataset/test_wav'\n",
        "\n",
        "path_to_train_img='/content/drive/MyDrive/prism_dataset/train_img'\n",
        "path_to_test_img='/content/drive/MyDrive/prism_dataset/test_img'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PM_Ha6K3RhO"
      },
      "source": [
        "import skimage.io\n",
        "\n",
        "def scale_minmax(X, min=0.0, max=1.0):\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (max - min) + min\n",
        "    return X_scaled"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5embls43TpI"
      },
      "source": [
        "# FOR Training wav to images\n",
        "for filename in os.listdir(path_to_train_wav):\n",
        "    wavefile = path_to_train_wav  + '/' + str(filename)\n",
        "    y, sr = librosa.load(wavefile, mono=True,duration=1,sr=16000)\n",
        "    N = 16000-len(y)\n",
        "    y=np.pad(y, (0, N), 'constant')\n",
        "    mfcc = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "    \n",
        "    img = scale_minmax(mfcc, 0, 255).astype(np.uint8) \n",
        "    \n",
        "    skimage.io.imsave(path_to_train_img + '/' + str(filename[:-4]) + '.png', img)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # FOR Testing wav to images\n",
        "# for filename in os.listdir(pathtotestwav):\n",
        "#     songname = pathtotestwav  + '/' + str(filename)\n",
        "#     y, sr = librosa.load(songname, mono=True,duration=1,sr=16000)\n",
        "#     N = 16000-len(y)\n",
        "#     y=np.pad(y, (0, N), 'constant')\n",
        "#     mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
        "   \n",
        "#     img = scale_minmax(mfcc, 0, 255).astype(np.uint8)\n",
        "   \n",
        "#     skimage.io.imsave(pathtotestimg + '/' + str(filename[:-4]) + '.png', img)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYscTNdU4KLy"
      },
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "labels = 'abhishek anmol anurag deewanshu himanshu kishan mayank narender neeraj prince ritvik sayan shiv shreyas shubham siddharth sourav swaraj utkarsh vikrant'.split()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW5kmEv_4YkB",
        "outputId": "d94c5831-36a0-4749-d885-594f9e8476d0"
      },
      "source": [
        "# FOR Training images\n",
        "train_data = []\n",
        "train_label = []\n",
        "j=1\n",
        "\n",
        "for photos in os.listdir(path_to_train_img):\n",
        "  image_array=cv2.imread(path_to_train_img + '/' + str(photos),0)\n",
        "  # if j==1:\n",
        "  #   cv2_imshow(image_array)\n",
        "  #   j+=1\n",
        "  image_array = np.expand_dims(image_array, axis=-1)\n",
        "  # image_array=cv2.imread(f'./drive/MyDrive/dataset_prism/dataset_img/train_img/{photos}')\n",
        "  # image_array=Image.open(f'./drive/MyDrive/dataset_img/{photos}')\n",
        "  # image_array = np.asarray(image_array)\n",
        "  train_data.append(image_array)\n",
        "  for temp in range(len(labels)):\n",
        "    if labels[temp]==photos[:-7]:\n",
        "      train_label.append(temp)\n",
        "      break\n",
        "\n",
        "\n",
        "#Converting training images to training arrays\n",
        "train_data = np.asarray(train_data)\n",
        "train_label = np.asarray(train_label)\n",
        "print(train_data.shape)\n",
        "print(train_label.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 128, 32, 1)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFUQetFn4blh"
      },
      "source": [
        "# # FOR Testing images\n",
        "# test_data = []\n",
        "# test_label = []\n",
        "#                                     # Files = ['Dog', 'Cat']\n",
        "#                                     # label_val = 0\n",
        "# for photos in os.listdir(pathtotestimg):\n",
        "#                                     # print(photos)\n",
        "#   image_array=cv2.imread(pathtotestimg + '/' + str(photos))\n",
        "#   image_array = np.expand_dims(image_array, axis=-1)\n",
        "#                                     # image_array=Image.open(f'./drive/MyDrive/dataset_img/{photos}')\n",
        "#                                     # image_array = np.asarray(image_array)\n",
        "#   test_data.append(image_array)\n",
        "#   for temp in range(len(labels)):\n",
        "#     if labels[temp]==photos[:-7]:\n",
        "#       test_label.append(temp)\n",
        "#       break\n",
        "  \n",
        "#                                     #Converting testing images to testing arrays\n",
        "# test_data = np.asarray(test_data)\n",
        "# test_label = np.asarray(test_label)\n",
        "# print(test_data.shape)\n",
        "# print(test_label.shape)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTCbTxaX5Al4",
        "outputId": "40390273-f1da-45de-bc2d-304a20fc371a"
      },
      "source": [
        "x_train=train_data\n",
        "y_train=train_label\n",
        "# X_test=test_data\n",
        "# y_test=test_label\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 128, 32, 1)\n",
            "(1000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vn7TtHMX5Cyt"
      },
      "source": [
        "num_classes = 20\n",
        "epochs = 20\n",
        " \n",
        "def euclid_dis(vects):\n",
        "  x,y = vects\n",
        "  sum_square = K.sum(K.square(x-y), axis=1, keepdims=True)\n",
        "  return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
        " \n",
        "def eucl_dist_output_shape(shapes):\n",
        "    shape1, shape2 = shapes\n",
        "    return (shape1[0], 1)\n",
        " \n",
        "def contrastive_loss(y_true, y_pred):\n",
        "    y_true=tf.dtypes.cast(y_true, tf.float64)\n",
        "    y_pred=tf.dtypes.cast(y_pred, tf.float64)\n",
        "    margin = 1\n",
        "    square_pred = K.square(y_pred)\n",
        "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
        "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fd8TbM15KYA"
      },
      "source": [
        "# PYIMAGESEARCH\n",
        "def create_pairs(images, labels):\n",
        "\t# initialize two empty lists to hold the (image, image) pairs and\n",
        "\t# labels to indicate if a pair is positive or negative\n",
        "\tpairImages = []\n",
        "\tpairLabels = []\n",
        "  # calculate the total number of classes present in the dataset\n",
        "\t# and then build a list of indexes for each class label that\n",
        "\t# provides the indexes for all examples with a given label\n",
        "\tnumClasses = len(np.unique(labels))\n",
        "\tidx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
        "  # loop over all images\n",
        "\tfor idxA in range(len(images)):\n",
        "\t\t# grab the current image and label belonging to the current\n",
        "\t\t# iteration\n",
        "\t\tcurrentImage = images[idxA]\n",
        "\t\tlabel = labels[idxA]\n",
        "\t\t# randomly pick an image that belongs to the *same* class\n",
        "\t\t# label\n",
        "\t\tidxB = np.random.choice(idx[label])\n",
        "\t\tposImage = images[idxB]\n",
        "\t\t# prepare a positive pair and update the images and labels\n",
        "\t\t# lists, respectively\n",
        "\t\tpairImages.append([currentImage, posImage])\n",
        "\t\tpairLabels.append(1)\n",
        "    # grab the indices for each of the class labels *not* equal to\n",
        "\t\t# the current label and randomly pick an image corresponding\n",
        "\t\t# to a label *n ot* equal to the current label\n",
        "\t\tnegIdx = np.where(labels != label)[0]\n",
        "\t\tnegImage = images[np.random.choice(negIdx)]\n",
        "\t\t# prepare a negative pair of images and update our lists\n",
        "\t\tpairImages.append([currentImage, negImage])\n",
        "\t\tpairLabels.append(0)\n",
        "\t# return a 2-tuple of our image pairs and labels\n",
        "\treturn (np.array(pairImages), np.array(pairLabels))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cX9sc0D5puG",
        "outputId": "c6b2bd8a-b1c2-4479-b05e-40d06e369be3"
      },
      "source": [
        "def create_base_net(input_shape):\n",
        "   \n",
        "  input = Input(shape = input_shape)\n",
        "  x = Conv2D(4, (5,5), activation = 'tanh')(input)\n",
        "  x = AveragePooling2D(pool_size = (2,2))(x)\n",
        "  x = Conv2D(16, (5,5), activation = 'tanh')(x)\n",
        "  x = AveragePooling2D(pool_size = (2,2))(x)\n",
        "  x = Flatten()(x)\n",
        "  x = Dense(20, activation = 'tanh')(x)\n",
        "  model = Model(input, x)\n",
        "  model.summary()\n",
        "  return model\n",
        " \n",
        "def compute_accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    pred = y_pred.ravel() < 0.5\n",
        "    return np.mean(pred == y_true)\n",
        " \n",
        " \n",
        "def accuracy(y_true, y_pred):\n",
        "    '''Compute classification accuracy with a fixed threshold on distances.\n",
        "    '''\n",
        "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
        " \n",
        " \n",
        "# the data, split between train and test sets\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        " \n",
        " \n",
        "# x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
        "# x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "input_shape = (128, 32,1)\n",
        "print(x_train.shape)\n",
        "x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "# y_train = y_train.astype('float32')\n",
        "# y_test = y_test.astype('float32')\n",
        "x_train /= 255\n",
        "# x_test /= 255\n",
        " \n",
        "input_shape = x_train.shape[1:]\n",
        "input_shape = (128, 32, 1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 128, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FPU04vj52BI"
      },
      "source": [
        "# digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
        "tr_pairs, tr_y = create_pairs(x_train, y_train)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-vRa7V2J57YI",
        "outputId": "b5198e45-0ac6-4cf1-824e-5c12a66bb8ab"
      },
      "source": [
        "base_network = create_base_net(input_shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 32, 1)]      0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 124, 28, 4)        104       \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 62, 14, 4)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 58, 10, 16)        1616      \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 29, 5, 16)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2320)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                46420     \n",
            "=================================================================\n",
            "Total params: 48,140\n",
            "Trainable params: 48,140\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSkMOM1_6Dwl",
        "outputId": "00894752-2976-450c-d6e9-f2d79efe842a"
      },
      "source": [
        "input_a = Input(shape=input_shape)\n",
        "input_b = Input(shape=input_shape)\n",
        " \n",
        "processed_a = base_network(input_a)\n",
        "processed_b = base_network(input_b)\n",
        " \n",
        "distance = Lambda(euclid_dis,\n",
        "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
        " \n",
        "model = Model([input_a, input_b], distance)\n",
        "#train\n",
        "model.compile(loss=contrastive_loss, optimizer='adam', metrics=[accuracy])\n",
        "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
        "          batch_size=128,\n",
        "          epochs=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "16/16 [==============================] - 8s 390ms/step - loss: 0.3496 - accuracy: 0.5105\n",
            "Epoch 2/20\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 0.2477 - accuracy: 0.5953\n",
            "Epoch 3/20\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.2279 - accuracy: 0.6253\n",
            "Epoch 4/20\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.2179 - accuracy: 0.6454\n",
            "Epoch 5/20\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.2108 - accuracy: 0.6729\n",
            "Epoch 6/20\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.2058 - accuracy: 0.6893\n",
            "Epoch 7/20\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.2019 - accuracy: 0.6997\n",
            "Epoch 8/20\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.1976 - accuracy: 0.7089\n",
            "Epoch 9/20\n",
            "16/16 [==============================] - 6s 388ms/step - loss: 0.1950 - accuracy: 0.7149\n",
            "Epoch 10/20\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.1921 - accuracy: 0.7227\n",
            "Epoch 11/20\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.1902 - accuracy: 0.7264\n",
            "Epoch 12/20\n",
            "16/16 [==============================] - 6s 395ms/step - loss: 0.1877 - accuracy: 0.7326\n",
            "Epoch 13/20\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.1853 - accuracy: 0.7421\n",
            "Epoch 14/20\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.1845 - accuracy: 0.7393\n",
            "Epoch 15/20\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.1819 - accuracy: 0.7407\n",
            "Epoch 16/20\n",
            "16/16 [==============================] - 6s 392ms/step - loss: 0.1806 - accuracy: 0.7431\n",
            "Epoch 17/20\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.1784 - accuracy: 0.7603\n",
            "Epoch 18/20\n",
            "16/16 [==============================] - 6s 389ms/step - loss: 0.1780 - accuracy: 0.7494\n",
            "Epoch 19/20\n",
            "16/16 [==============================] - 6s 390ms/step - loss: 0.1789 - accuracy: 0.7491\n",
            "Epoch 20/20\n",
            "16/16 [==============================] - 6s 391ms/step - loss: 0.1766 - accuracy: 0.7541\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7e753d8a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE43amCs6G1k"
      },
      "source": [
        "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6C785kfC6vTC",
        "outputId": "5deb5b12-ac88-4340-87bf-4a6c9fb9c5cf"
      },
      "source": [
        "y_pred[:9]"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.0170438e-01],\n",
              "       [6.6186249e-01],\n",
              "       [5.0869775e-01],\n",
              "       [7.0596337e-01],\n",
              "       [2.8502491e-01],\n",
              "       [7.6076597e-01],\n",
              "       [2.2653650e-01],\n",
              "       [6.1600655e-01],\n",
              "       [3.1622776e-04]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPNObRmi6yfP",
        "outputId": "057349db-8d6d-43b0-8611-1e94593504ae"
      },
      "source": [
        "tr_y[10:20]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeE9FlJN7B8k",
        "outputId": "5287ee07-f586-4751-e92b-615d5bfbcd44"
      },
      "source": [
        "y_pred = y_pred.ravel() < 0.5\n",
        "y_pred[10:20]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False, False,  True, False,  True, False,  True,\n",
              "       False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmDA7b7X7J3Z",
        "outputId": "90fddff2-4d3c-4db8-b253-356dc28e9d6b"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
        "print(sklearn.metrics.matthews_corrcoef(tr_y, y_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5351672659099802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fVZEDLW7aJy",
        "outputId": "a857ea93-1433-4eb9-e059-36944c22aaea"
      },
      "source": [
        "print(sklearn.metrics.roc_auc_score(tr_y, y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7675000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJ2WuUdW7czS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}